{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa04706",
   "metadata": {},
   "source": [
    "# Experiments and Runs\n",
    "\n",
    "## Defining an Experiment\n",
    "\n",
    "In the DRYTorch framework, an experiment is a fully reproducible execution of code defined entirely by a configuration file. For example, this design implies that:\n",
    "\n",
    "- a result obtained by modifying the configuration file (e.g., changing the optimizer) constitutes a new experiment instance.\n",
    "\n",
    "-  a parameter sweep (or grid search), when fully described within the configuration file, is considered a single experiment.\n",
    "\n",
    "To define an experiment, you should subclass or annotate DRYTorch's Experiment class, specifying the required configuration type. The Experiment class needs an unique name for each instance and also accepts optional tags and a designated output directory for the run, which other framework components will utilize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d771352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "\n",
    "from typing import TypeAlias\n",
    "\n",
    "from drytorch import Experiment as GenericExperiment\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class SimpleConfig:\n",
    "    \"\"\"A simple configuration.\"\"\"\n",
    "\n",
    "    batch_size: int\n",
    "\n",
    "\n",
    "class MySubclassedExperiment(GenericExperiment[SimpleConfig]):\n",
    "    \"\"\"Class for Simple Experiments.\"\"\"\n",
    "\n",
    "\n",
    "# alternatively:\n",
    "MyAnnotatedExperiment: TypeAlias = GenericExperiment[SimpleConfig]\n",
    "\n",
    "my_config = SimpleConfig(32)\n",
    "my_experiment = MySubclassedExperiment(\n",
    "    my_config,\n",
    "    name='SimpleExp',\n",
    "    par_dir='.',\n",
    "    tags=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0961f4",
   "metadata": {},
   "source": [
    "# Starting a Run\n",
    "In the DRYTorch framework, a run is a single execution instance of an experiment's code. Multiple runs of the same experiment—for example, by varying the random seed—are used to replicate and validate results.\n",
    "\n",
    "You initiate a run instance using the Experiment's create_run method. This instance serves as a context manager (with block) for the experiment's execution code.\n",
    "\n",
    "The run's ID is a timestamp by default, but you can specify a unique, descriptive name.\n",
    "\n",
    "You can resume a run by specifying its unique name in create_run. If a name is not provided, DRYTorch attempts to resume the last recorded run.\n",
    "\n",
    "Note: DRYTorch maintains a run registry on the local disk to track and manage all run IDs and states.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cca804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-11 22:36:04] - Running experiment: SimpleExp.\n",
      "[2025-10-11 22:36:04] - Running experiment: SimpleExp.\n"
     ]
    }
   ],
   "source": [
    "def implement_experiment() -> None:\n",
    "    \"\"\"Here should the code for the experiment.\"\"\"\n",
    "\n",
    "\n",
    "with my_experiment.create_run() as run:\n",
    "    first_id = run.id\n",
    "    implement_experiment()\n",
    "\n",
    "\n",
    "with my_experiment.create_run(resume=True) as run:\n",
    "    second_id = run.id\n",
    "    implement_experiment()\n",
    "\n",
    "if first_id != second_id:\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f0a55",
   "metadata": {},
   "source": [
    "For convenience, especially in interactive environments like notebooks, you can manually start and stop a run, avoiding the context manager.\n",
    "\n",
    "To do this, use the Experiment's start_run() method and ensure you explicitly call run.stop() when finished.\n",
    "\n",
    "Warning: If you forget to call run.stop(), the run may not be properly recorded or finalized. While DRYTorch uses weak references to attempt cleanup at the end of the session, this behavior is unreliable and should not be depended upon for correct run logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d209a180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-11 22:36:04] - Running experiment: SimpleExp.\n"
     ]
    }
   ],
   "source": [
    "run = my_experiment.create_run()\n",
    "run.start()\n",
    "run.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bea30a",
   "metadata": {},
   "source": [
    "## Trackers\n",
    "The previous output contains a log generated when starting the run. The Experiment class allows you to fully customize which trackers will be active for the experiment, letting you replace or augment the default logging behavior (see the notebook about trackers for more detail)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9492dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_experiment.trackers.remove('BuiltinLogger')\n",
    "\n",
    "with my_experiment.create_run(resume=True) as run:\n",
    "    second_id = run.id\n",
    "    implement_experiment()\n",
    "\n",
    "# no output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc5946a",
   "metadata": {},
   "source": [
    "## Global configuration\n",
    "\n",
    "It is possible to access the configuration file directly from the Experiment class when the a run is on. Otherwise, this operation will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d905c0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Configuration accessed outside the run'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from drytorch.core import exceptions\n",
    "\n",
    "\n",
    "def get_batch() -> int:\n",
    "    \"\"\"Retrieve the batch size setting.\"\"\"\n",
    "    return MySubclassedExperiment.get_config().batch_size\n",
    "\n",
    "\n",
    "with my_experiment.create_run():\n",
    "    get_batch()\n",
    "\n",
    "try:\n",
    "    get_batch()\n",
    "except (exceptions.AccessOutsideScopeError, exceptions.NoActiveExperimentError):\n",
    "    err_str = 'Configuration accessed when no run is on.'\n",
    "else:\n",
    "    err_str = ''\n",
    "\n",
    "\n",
    "err_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bedc99",
   "metadata": {},
   "source": [
    "DRYTorch discourages information leakage between runs to ensure reproducibility.\n",
    "\n",
    "The framework explicitly prevents constructing a Model instance based on a module registered in a previous run. This isolation ensures that each run starts from a clean state defined solely by its configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568e970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-11 22:36:04] - Running experiment: Experiment.\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "from drytorch import Model\n",
    "\n",
    "\n",
    "my_second_exp = MyAnnotatedExperiment(my_config)\n",
    "\n",
    "with my_experiment.create_run():\n",
    "    first_model = Model(Linear(1, 1))\n",
    "\n",
    "with my_second_exp.create_run():\n",
    "    second_model = Model(first_model.module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
